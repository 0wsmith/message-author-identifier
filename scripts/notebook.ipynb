{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d885c90",
   "metadata": {},
   "source": [
    "# Identifying Message Authors based on Message Content\n",
    "#### Wilson Smith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c6298",
   "metadata": {},
   "source": [
    "The existence of an algorithm to successfully identify message authors based on details of the message content can reduce anonymity to a certain degree. While this may be worrisome, it does not de-anonymize everybody. Particularly, because the model has to be trained to identify a specific actor by being trained on that same actor. So an individual can be targeted only if there is sufficient accessible data that can be linked to that individual already. Moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6066cd8",
   "metadata": {},
   "source": [
    "The idea here is to identify who said which messages based on different properties of a message. These properties include, but are not limited to word choice and typos. All of these messages can come from social media platforms, message boards, forum sites, text messages, or wherever user-generated conversational text happens to be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8526eb",
   "metadata": {},
   "source": [
    "For this project, a set of python libraries will be used to collect, aggregate, process, and analyze the data. They are imported in this block of python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99dd242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "\n",
    "# data management\n",
    "import sqlite3\n",
    "import os\n",
    "import json\n",
    "\n",
    "# internet data collection\n",
    "import requests\n",
    "\n",
    "# utilities\n",
    "import re\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import time\n",
    "from calendar import Calendar as cal\n",
    "\n",
    "# this function exists because calendar's itermonthdates is not exclusive to the entered month.\n",
    "def month_days(year, month):\n",
    "    return map(\n",
    "        lambda x: x.day,\n",
    "        filter(\n",
    "            lambda x: x.month==month,\n",
    "            cal().itermonthdates(year, month)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985f6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook file is not at the root of the directory tree.\n",
    "if not os.path.exists('.gitignore'):\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde832aa",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcaad85",
   "metadata": {},
   "source": [
    "## Data Collection & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946103a",
   "metadata": {},
   "source": [
    "The directory structure of the data folder will be as follows:\n",
    "\n",
    "```\n",
    "data/\n",
    " ┣ irc/\n",
    " ┃ ┣ ubuntu_20150101.txt  logfile for #ubuntu on 01/01/2015\n",
    " ┃ ┃ ...\n",
    " ┃ ┗ ubuntu_20211231.txt  logfile for #ubuntu on 31/12/2021\n",
    " ┣ discord/\n",
    " ┃ ┣ token                authentication token for discord\n",
    " ┃ ┗ channel_ids          lists of chats to scrape\n",
    " ┣ irc.db                 sqlite3 database of messages from irc channels\n",
    " ┣ discord.db             sqlite3 database of messages from discord\n",
    " ┗ words                  local copy of a dictionary of words separated by newlines\n",
    "```\n",
    "\n",
    "This structure will be created with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173e1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_path(tree):\n",
    "    for k,v in tree.items():\n",
    "        if not os.path.exists(k):\n",
    "            os.mkdir(k)\n",
    "        os.chdir(k)\n",
    "        ensure_path(v)\n",
    "        os.chdir('..')\n",
    "        \n",
    "ensure_path({\n",
    "    'data': {\n",
    "        'irc': {},\n",
    "        'discord': {},\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c530c4",
   "metadata": {},
   "source": [
    "### IRC\n",
    "IRC has four main types of channel messages:\n",
    "1.  User messages (the most common).\n",
    "\n",
    "    `(date) (sender name) (message content)`\n",
    "   \n",
    "    Some clients have a reply feature.\n",
    "    It prefixes the message with the replied-to user's name.\n",
    "\n",
    "2.  Status \"/me\" messages.\n",
    "\n",
    "    `(date)  * (sender name) (message content)`\n",
    "    \n",
    "3.  Name change messages.\n",
    "\n",
    "    `(system prefix) (old name) is now known as (new name)`\n",
    "   \n",
    "4.  System changes.\n",
    "\n",
    "    This includes things like permissions and other miscellaneous moderation actions.\n",
    "    In most conversation, they don't matter.\n",
    "\n",
    "For this example, I've decided to use the archived versions of the `#ubuntu` IRC channel.\n",
    "\n",
    "These are publically accessible at [irclogs.ubuntu.com](https://irclogs.ubuntu.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44968d34",
   "metadata": {},
   "source": [
    "First, to avoid abusing ubuntu's servers, a local cache of the relevant logfiles were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861e6598",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2015, 2022):\n",
    "    for month in range(1, 12 + 1):\n",
    "        for day in month_days(2020, month):\n",
    "            filename = f\"data/irc/ubuntu_{year:04}{month:02}{day:02}.txt\"\n",
    "            if not os.path.exists(filename):\n",
    "                resp = requests.get(f\"https://irclogs.ubuntu.com/{year:04}/{month:02}/{day:02}/%23ubuntu.txt\")\n",
    "                if resp.status_code == 200:\n",
    "                    with open(filename, 'w+') as f:\n",
    "                        f.write(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f844ce4",
   "metadata": {},
   "source": [
    "Then unique ID is necessary for grouping the chat message authors by actor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14245aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (name, database) -> (database with name, index of name in database)\n",
    "def name_to_id(name, db):\n",
    "    for k,v in db.items():\n",
    "        if name == v[-1]:\n",
    "            return k\n",
    "    new_id = len(db)\n",
    "    db[new_id] = [name]\n",
    "    return new_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebbf78",
   "metadata": {},
   "source": [
    "IRC user name change system message affect the unique ID calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf3244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (old name, new name, database) -> (database with names, index of name in database)\n",
    "def renamed(name_old, name_new, db):\n",
    "    for k,v in db.items():\n",
    "        if name_old == v[-1]:\n",
    "            v.append(name_new)\n",
    "            return k\n",
    "    for k,v in db.items():\n",
    "        try:\n",
    "            if name_old == v[-2]:\n",
    "                if name_new == v[-1]:\n",
    "                    return k\n",
    "        except: pass\n",
    "    new_id = len(db)\n",
    "    db[new_id] = [name_old, name_new]\n",
    "    return new_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d27de8",
   "metadata": {},
   "source": [
    "The grand total processing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f34e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the message log for `#ubuntu` for a particular day.\n",
    "def irc_ubuntu_date(year, month, day, senders={}):\n",
    "    filename = f\"data/irc/ubuntu_{year:04}{month:02}{day:02}.txt\"\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        print(filename, \"does not exist. 404?\")\n",
    "        return None\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        text = ''.join(f.readlines())\n",
    "        \n",
    "    df = pd.DataFrame(columns=[\n",
    "        'date',\n",
    "        'sender',\n",
    "        'reply_to',\n",
    "        'message'\n",
    "    ])\n",
    "    \n",
    "    for line in text.split('\\n'):\n",
    "        \n",
    "        match = re.search(r\"^\\[(\\d\\d):(\\d\\d)\\] <([^>]+)>\\s*(([^\\s:]+):)?\\s*(.*)$\", line)\n",
    "        if match:\n",
    "            date = datetime.datetime(year, month, day, int(match[1]), int(match[2]))\n",
    "            df = df.append({\n",
    "                'date': date,\n",
    "                'sender': name_to_id(match[3], senders),\n",
    "                'reply_to': None if match[5] is None else name_to_id(match[5], senders),\n",
    "                'message': match[6]\n",
    "            }, ignore_index=True)\n",
    "            continue\n",
    "        \n",
    "        match = re.search(r\"=== (.+) is now known as (.+)$\", line)\n",
    "        if match:\n",
    "            renamed(match[1], match[2], senders)\n",
    "            continue\n",
    "        \n",
    "        match = re.search(r\"^\\[(\\d\\d):(\\d\\d)\\]  \\* ([^\\s]+) (.*)$\", line)\n",
    "        if match:\n",
    "            date = datetime.datetime(year, month, day, int(match[1]), int(match[2]))\n",
    "            df = df.append({\n",
    "                'date': date,\n",
    "                'sender': name_to_id(match[3], senders),\n",
    "                'reply_to': None,\n",
    "                'message': match[4]\n",
    "            }, ignore_index=True)\n",
    "            continue\n",
    "            \n",
    "        if line == \"\":\n",
    "            continue\n",
    "        \n",
    "        print('weird line format', line)\n",
    "\n",
    "    return df, senders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ce7c9",
   "metadata": {},
   "source": [
    "Python [DataFrames](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) to store the scraped data for ease of manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6675e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_irc_ubuntu = pd.DataFrame(columns=[\n",
    "    'date',\n",
    "    'sender',\n",
    "    'reply_to',\n",
    "    'message'\n",
    "])\n",
    "df_irc_ubuntu_names = pd.DataFrame(columns=[\n",
    "    'id',\n",
    "    'index',\n",
    "    'name',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d24c56",
   "metadata": {},
   "source": [
    "Pre-process all of 2015, then cache it to an sqlite database. If this database table already exists, load it (saves tens of hours).\n",
    "\n",
    "[Some](https://irclogs.ubuntu.com/2015/05/22/%23ubuntu.txt) [dates](https://irclogs.ubuntu.com/2015/11/09/%23ubuntu.txt) are missing proper logfiles. More on this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90f5d9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded df_irc_ubuntu_2015\n",
      "loaded df_irc_ubuntu_2015_names\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"data/irc.db\")\n",
    "year = 2015\n",
    "\n",
    "try:\n",
    "    df_irc_ubuntu = pd.read_sql_query(f\"SELECT * FROM irc_ubuntu_{year}\", conn)\n",
    "    print(f\"loaded df_irc_ubuntu_{year}\")\n",
    "    \n",
    "    df_irc_ubuntu_names = pd.read_sql_query(f\"SELECT * FROM irc_ubuntu_{year}_names\", conn)\n",
    "    print(f\"loaded df_irc_ubuntu_{year}_names\")\n",
    "    \n",
    "except:\n",
    "    for month in range(1, 12 + 1):\n",
    "        for day in month_days(year, month):\n",
    "            messages, senders = irc_ubuntu_date(year, month, day, senders=sender_list)\n",
    "            df_irc_ubuntu = df_irc_ubuntu.append(messages, ignore_index=True)\n",
    "            print(\"processed\", year, month, day)\n",
    "            \n",
    "    df_irc_ubuntu.to_sql(f\"irc_ubuntu_{year}\", conn)\n",
    "    print(f\"logged df_irc_ubuntu_{year}\")\n",
    "\n",
    "    for k,v in senders.items():\n",
    "        for i,v in enumerate(v):\n",
    "            df_irc_ubuntu_names = df_irc_ubuntu_names.append({\n",
    "                'id': k,\n",
    "                'index': i,\n",
    "                'name': v,\n",
    "            }, ignore_index=True)\n",
    "    \n",
    "    df_irc_ubuntu_names.to_sql(f\"irc_ubuntu_{year}_names\", conn)\n",
    "    print(f\"logged df_irc_ubuntu_{year}_names\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc7c7fc",
   "metadata": {},
   "source": [
    "### Discord\n",
    "Discord has several types of messages. They are stored and transferred in JSON format.\n",
    "The [official documentation](https://discord.com/developers/docs/resources/channel#message-object) describes the general format for messages.\n",
    "\n",
    "The fields relevant for this experiment are:\n",
    "```\n",
    "    {\n",
    "        author: {\n",
    "            id,                 internal user id\n",
    "            name,               text display name\n",
    "            bot?,               boolean: is the user a bot (optional)\n",
    "            ...\n",
    "        },\n",
    "        content,                unformatted markdown message content\n",
    "        attachments,            array of attachment objects which have links to the file.\n",
    "        timestamp,              send time in ISO8601 format\n",
    "        referenced_message?,    the message this message was sent as a reply to (optional)\n",
    "        type,                   enum for what kind of message this is\n",
    "        ...\n",
    "    }\n",
    "```\n",
    "Fields labeled with a question mark `?` may not appear.\n",
    "\n",
    "This format covers every potential message that can be viewed by users.\n",
    "For this, messages with nonempty content will be used.\n",
    "\n",
    "Message content can also include mentions of users in the format `<@USER_ID>` where `USER_ID` is the numeric internal user id. These will remain in the processed data set, as when an account's data is anonymized, the message content is completely unaltered.\n",
    "\n",
    "The author object is calculated when the message is delivered to the client. Any updates to the author will show up in old messages. That being said, there is only one visible username at a time.\n",
    "\n",
    "These messages are _not_ publically accessible. Consent per user that appears in any message was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39815696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discord_channel_messages(authorization_token, channel_id):\n",
    "    messages = []\n",
    "    headers = {\n",
    "        'User-Agent': 'I am scraping my own messages for a data science project. If you need to contact me, message me on this account.',\n",
    "        'Accept': '*/*',\n",
    "        'Authorization': authorization_token,\n",
    "    }\n",
    "    first_message = 0\n",
    "    \n",
    "    while True:\n",
    "        resp = requests.get(\n",
    "            f\"https://discord.com/api/v9/channels/{channel_id}/messages?limit=100&after={first_message}\",\n",
    "            headers = headers\n",
    "        )\n",
    "        data = json.loads(resp.text)\n",
    "        \n",
    "        if isinstance(data, dict) and 'retry_after' in data.keys():\n",
    "            time.sleep(data['retry_after'] + 1)\n",
    "            continue\n",
    "        \n",
    "        messages += data\n",
    "        first_message = data[0]['id']\n",
    "        \n",
    "        if len(data) < 100:\n",
    "            break\n",
    "    \n",
    "    return [\n",
    "        [\n",
    "            dateutil.parser.isoparse(m['timestamp']),\n",
    "            m['author']['id'],\n",
    "            m['content'],\n",
    "            not not m['edited_timestamp'],\n",
    "        ] for m in messages\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99b8dd",
   "metadata": {},
   "source": [
    "Load private authentication and location parameters:\n",
    "\n",
    "`data/discord/token` is your user authentication token to access your data on Discord.\n",
    "\n",
    "`data/discord/channel_ids` is a list of channel IDs to scrape all the messages from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1be51d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/discord/token', 'r') as f:\n",
    "    discord_token = ''.join(f.readlines()).strip()\n",
    "    \n",
    "with open('data/discord/channel_ids', 'r') as f:\n",
    "    discord_channels = [cid.strip() for cid in f.readlines() if len(cid) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d676b51",
   "metadata": {},
   "source": [
    "Proceeding to log and cache the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "137375d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded channel #0\n",
      "loaded channel #1\n",
      "loaded channel #2\n",
      "loaded channel #3\n"
     ]
    }
   ],
   "source": [
    "conn_discord = sqlite3.connect(\"data/discord.db\")\n",
    "\n",
    "discord_all = {}\n",
    "\n",
    "for index, channel in enumerate(discord_channels):\n",
    "    try:\n",
    "        discord_all[index] = pd.read_sql_query(f\"SELECT * FROM discord_{channel}\", conn_discord)\n",
    "        print(f\"loaded channel #{index}\")\n",
    "        \n",
    "    except:\n",
    "        discord_all[index] = pd.DataFrame(\n",
    "            data = discord_channel_messages(discord_token, channel),\n",
    "            columns=[\n",
    "                'date',\n",
    "                'sender',\n",
    "                'message',\n",
    "                'edited',\n",
    "            ]\n",
    "        )\n",
    "        discord_all[index].to_sql(f\"discord_{channel}\", conn_discord)\n",
    "        print(f\"logged channel #{index}\")\n",
    "\n",
    "conn_discord.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156e350",
   "metadata": {},
   "source": [
    "### Missing data?\n",
    "For IRC, some days were missing logfiles.\n",
    "Imputing enough data to fill the gaps is very difficult considering the number of parameters.\n",
    "The gaps will be used as boundaries.\n",
    "\n",
    "For Discord, some messages may have been deleted or edited.\n",
    "In the case of a deleted message, there is no evidence of it.\n",
    "So the likelihood of missing context or messages will have to be accounted for in the model.\n",
    "In the case of an editied message, the most frequent is a spelling correction.\n",
    "Because the actor who wrote the original message also edited the message, it should not matter so much what changed.\n",
    "\n",
    "In short, the missing data can't reliably be recovered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f63e9a",
   "metadata": {},
   "source": [
    "### Incorrect data?\n",
    "It is possible that data may be incorrect. There are a few ways that come to mind:\n",
    "1. logfiles with mislabeled dates\n",
    "2. name matching/impersonation of a user\n",
    "3. quoting\n",
    "4. manipulation by platform administrator\n",
    "\n",
    "For mislabeling, this can be solved by looking at each day individually.\n",
    "For the collected data, it can only be a problem for IRC.\n",
    "\n",
    "Impersonation is harder to solve.\n",
    "If \"Tom\" disconnects, unless he was a registered user, someone else may connect with the name \"Tom\" in IRC.\n",
    "Multiple people may also use the same account, so there may be some sort of bimodal distribution of features for one account.\n",
    "\n",
    "For quoting, in IRC, it is infrequent due to the message size limitations. In Discord, the quote user feature is builtin, and shows up in a different field from the message content. So this shouldn't be a direct issue in conflict between users. It may only appear if two users quote the same material. But this should be accounted for by a model.\n",
    "\n",
    "For administrator manipulation, nothing can be done. This is highly unlikely on smaller 1-to-1 message logs, but may exist on IRC platforms if someone posts something against the platform's terms of service for one reason or another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f13cc6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab25584",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0342c68b",
   "metadata": {},
   "source": [
    "Now that the data has been aggregated successfully, we should analyze different properties of the messages to build a proper and functional model that can (somewhat) reliably determine which actor sent which message. For that, we need to calculate some statistics regarding the data set.\n",
    "\n",
    "To start, we will define what we mean by common terms for lingustic analyses:\n",
    "- document: an individual message\n",
    "- corpus: the entire conversation (over some range)\n",
    "- author/actor: message sender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b3200",
   "metadata": {},
   "source": [
    "Now, the first parameter that comes to mind is the usage freqency of particular words. A good statistic for this is [term frequency-inverse document frequency](http://tfidf.com/). This ranks each word based on the frequency in a message, weighted by the relative importance in the entire conversation.\n",
    "\n",
    "$$\\text{number of times }\\textit{word}\\text{ appears in the document} \\cdot \\ln\\left(\\frac{\\text{number of documents in corpus}}{\\text{number of documents with }\\textit{word}\\text{ in it}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f3cc6",
   "metadata": {},
   "source": [
    "As a precursor, the way that words are extracted from a document is abstracted out for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f49dabfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(document):\n",
    "    return re.split(r\"[\\s]+\", document.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f45807",
   "metadata": {},
   "source": [
    "And a standard list of words that are spelled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b49797c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/words\", \"r\") as f:\n",
    "    vocabulary_standard = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5b5c1",
   "metadata": {},
   "source": [
    "First, a function to count the word frequency in a list is constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "848318d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency_list(series):\n",
    "    vocabulary = {}\n",
    "    for document in series:\n",
    "        for word in words(document):\n",
    "            if not (word in vocabulary):\n",
    "                vocabulary[word] = 1\n",
    "            else:\n",
    "                vocabulary[word] += 1\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819366a",
   "metadata": {},
   "source": [
    "Now we need to determine the overall word frequency, and then the frequency per author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9562932e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>i</td>\n",
       "      <td>the</td>\n",
       "      <td>it</td>\n",
       "      <td>to</td>\n",
       "      <td>a</td>\n",
       "      <td>you</td>\n",
       "      <td>and</td>\n",
       "      <td>like</td>\n",
       "      <td>is</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11719</td>\n",
       "      <td>6261</td>\n",
       "      <td>5743</td>\n",
       "      <td>5148</td>\n",
       "      <td>4806</td>\n",
       "      <td>4682</td>\n",
       "      <td>3801</td>\n",
       "      <td>3378</td>\n",
       "      <td>3239</td>\n",
       "      <td>2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq(0)</th>\n",
       "      <td>4765</td>\n",
       "      <td>3789</td>\n",
       "      <td>3002</td>\n",
       "      <td>2728</td>\n",
       "      <td>2656</td>\n",
       "      <td>3510</td>\n",
       "      <td>1581</td>\n",
       "      <td>1088</td>\n",
       "      <td>1897</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq(1)</th>\n",
       "      <td>6954</td>\n",
       "      <td>2472</td>\n",
       "      <td>2741</td>\n",
       "      <td>2420</td>\n",
       "      <td>2150</td>\n",
       "      <td>1172</td>\n",
       "      <td>2220</td>\n",
       "      <td>2290</td>\n",
       "      <td>1342</td>\n",
       "      <td>1804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0     1     2     3     4     5     6     7     8     9\n",
       "word         i   the    it    to     a   you   and  like    is    ok\n",
       "freq     11719  6261  5743  5148  4806  4682  3801  3378  3239  2960\n",
       "freq(0)   4765  3789  3002  2728  2656  3510  1581  1088  1897  1156\n",
       "freq(1)   6954  2472  2741  2420  2150  1172  2220  2290  1342  1804"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = discord_all[3]\n",
    "\n",
    "word_frequency_in_corpus = pd.DataFrame(\n",
    "    data = np.array(list(\n",
    "        word_frequency_list(\n",
    "            dataset['message']\n",
    "        ).items()\n",
    "    )),\n",
    "    columns = [\n",
    "        'word',\n",
    "        'freq',\n",
    "    ]\n",
    ")\n",
    "\n",
    "total_vocabulary = word_frequency_in_corpus['word']\n",
    "\n",
    "word_frequency_in_corpus['freq'] = word_frequency_in_corpus['freq'].astype(int)\n",
    "word_frequency_in_corpus = word_frequency_in_corpus.sort_values(\n",
    "    by = 'freq',\n",
    "    ascending = False,\n",
    "    ignore_index = True\n",
    ")\n",
    "\n",
    "for index, sender in enumerate(dataset['sender'].unique()):\n",
    "    word_frequency_by_sender = pd.DataFrame(\n",
    "        data = np.array(list(\n",
    "            word_frequency_list(\n",
    "                dataset[dataset['sender'] == sender]['message']\n",
    "            ).items()\n",
    "        )),\n",
    "        columns = [\n",
    "            'word',\n",
    "            f\"freq({index})\",\n",
    "        ]\n",
    "    )\n",
    "    word_frequency_in_corpus = pd.merge(\n",
    "        word_frequency_in_corpus,\n",
    "        word_frequency_by_sender,\n",
    "        on = 'word',\n",
    "        how = 'left',\n",
    "    )\n",
    "\n",
    "word_frequency_in_corpus.fillna(0, inplace=True)\n",
    "\n",
    "word_frequency_in_corpus.head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6928203",
   "metadata": {},
   "source": [
    "Second, a function to count how many times a set of words occurs in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa654c06",
   "metadata": {},
   "source": [
    "Words that do not appear in the dictionary. This includes URLs, IPs, typos, abbreviations, numbers, and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1244fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>17</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>33</th>\n",
       "      <th>37</th>\n",
       "      <th>41</th>\n",
       "      <th>59</th>\n",
       "      <th>65</th>\n",
       "      <th>72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>ok</td>\n",
       "      <td>lol</td>\n",
       "      <td>im</td>\n",
       "      <td></td>\n",
       "      <td>dont</td>\n",
       "      <td>lmao</td>\n",
       "      <td>idk</td>\n",
       "      <td>?</td>\n",
       "      <td>thats</td>\n",
       "      <td>didnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2960</td>\n",
       "      <td>2388</td>\n",
       "      <td>2233</td>\n",
       "      <td>2130</td>\n",
       "      <td>1417</td>\n",
       "      <td>1307</td>\n",
       "      <td>1182</td>\n",
       "      <td>763</td>\n",
       "      <td>673</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq(0)</th>\n",
       "      <td>1156</td>\n",
       "      <td>901</td>\n",
       "      <td>695</td>\n",
       "      <td>1098</td>\n",
       "      <td>534</td>\n",
       "      <td>378</td>\n",
       "      <td>350</td>\n",
       "      <td>322</td>\n",
       "      <td>304</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq(1)</th>\n",
       "      <td>1804</td>\n",
       "      <td>1487</td>\n",
       "      <td>1538</td>\n",
       "      <td>1032</td>\n",
       "      <td>883</td>\n",
       "      <td>929</td>\n",
       "      <td>832</td>\n",
       "      <td>441</td>\n",
       "      <td>369</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           9     17    22    23    33    37    41   59     65     72\n",
       "word       ok   lol    im        dont  lmao   idk    ?  thats  didnt\n",
       "freq     2960  2388  2233  2130  1417  1307  1182  763    673    600\n",
       "freq(0)  1156   901   695  1098   534   378   350  322    304    260\n",
       "freq(1)  1804  1487  1538  1032   883   929   832  441    369    340"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency_in_corpus[~word_frequency_in_corpus['word'].isin(vocabulary_standard)].head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1a9d31",
   "metadata": {},
   "source": [
    "Words with dictionary-correct spellings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "885a38cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>i</td>\n",
       "      <td>the</td>\n",
       "      <td>it</td>\n",
       "      <td>to</td>\n",
       "      <td>a</td>\n",
       "      <td>you</td>\n",
       "      <td>and</td>\n",
       "      <td>like</td>\n",
       "      <td>is</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11719</td>\n",
       "      <td>6261</td>\n",
       "      <td>5743</td>\n",
       "      <td>5148</td>\n",
       "      <td>4806</td>\n",
       "      <td>4682</td>\n",
       "      <td>3801</td>\n",
       "      <td>3378</td>\n",
       "      <td>3239</td>\n",
       "      <td>2842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq(0)</th>\n",
       "      <td>4765</td>\n",
       "      <td>3789</td>\n",
       "      <td>3002</td>\n",
       "      <td>2728</td>\n",
       "      <td>2656</td>\n",
       "      <td>3510</td>\n",
       "      <td>1581</td>\n",
       "      <td>1088</td>\n",
       "      <td>1897</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq(1)</th>\n",
       "      <td>6954</td>\n",
       "      <td>2472</td>\n",
       "      <td>2741</td>\n",
       "      <td>2420</td>\n",
       "      <td>2150</td>\n",
       "      <td>1172</td>\n",
       "      <td>2220</td>\n",
       "      <td>2290</td>\n",
       "      <td>1342</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1     2     3     4     5     6     7     8     10\n",
       "word         i   the    it    to     a   you   and  like    is  that\n",
       "freq     11719  6261  5743  5148  4806  4682  3801  3378  3239  2842\n",
       "freq(0)   4765  3789  3002  2728  2656  3510  1581  1088  1897  1465\n",
       "freq(1)   6954  2472  2741  2420  2150  1172  2220  2290  1342  1377"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency_in_corpus[word_frequency_in_corpus['word'].isin(vocabulary_standard)].head(10).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
